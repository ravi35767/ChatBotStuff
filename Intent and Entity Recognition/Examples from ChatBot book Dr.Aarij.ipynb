{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Processing Textual Data (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataSource->  www.kaggle.com/snap/amazon-fine-food-reviews \n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "food_review = pd.read_csv(\"Reviews.csv\")\n",
    "food_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>277535</th>\n",
       "      <td>I love these chips! They always make a great h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253901</th>\n",
       "      <td>To add to the pile-on, really really hate the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495520</th>\n",
       "      <td>This stuff is the best. I put it on just about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373115</th>\n",
       "      <td>Organic India Tulsi tea is, to me, the absolut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547017</th>\n",
       "      <td>I have a German Shorthaired Pointer (3 yrs old...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text\n",
       "277535  I love these chips! They always make a great h...\n",
       "253901  To add to the pile-on, really really hate the ...\n",
       "495520  This stuff is the best. I put it on just about...\n",
       "373115  Organic India Tulsi tea is, to me, the absolut...\n",
       "547017  I have a German Shorthaired Pointer (3 yrs old..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the sample function from the pandas data frame, let’s randomly pick\n",
    "# the text of 1000 reviews and print the top rows \n",
    "\n",
    "food_review_text = pd.DataFrame(food_review[\"Text\"])\n",
    "food_review_text_1k = food_review_text.sample(n= 1000,random_state = 123)\n",
    "food_review_text_1k.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text    1000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_review_text_1k.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>tokenized_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>277535</th>\n",
       "      <td>I love these chips! They always make a great h...</td>\n",
       "      <td>[I, love, these, chips, !, They, always, make,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253901</th>\n",
       "      <td>To add to the pile-on, really really hate the ...</td>\n",
       "      <td>[To, add, to, the, pile-on, ,, really, really,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495520</th>\n",
       "      <td>This stuff is the best. I put it on just about...</td>\n",
       "      <td>[This, stuff, is, the, best, ., I, put, it, on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373115</th>\n",
       "      <td>Organic India Tulsi tea is, to me, the absolut...</td>\n",
       "      <td>[Organic, India, Tulsi, tea, is, ,, to, me, ,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547017</th>\n",
       "      <td>I have a German Shorthaired Pointer (3 yrs old...</td>\n",
       "      <td>[I, have, a, German, Shorthaired, Pointer, (, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  \\\n",
       "277535  I love these chips! They always make a great h...   \n",
       "253901  To add to the pile-on, really really hate the ...   \n",
       "495520  This stuff is the best. I put it on just about...   \n",
       "373115  Organic India Tulsi tea is, to me, the absolut...   \n",
       "547017  I have a German Shorthaired Pointer (3 yrs old...   \n",
       "\n",
       "                                        tokenized_reviews  \n",
       "277535  [I, love, these, chips, !, They, always, make,...  \n",
       "253901  [To, add, to, the, pile-on, ,, really, really,...  \n",
       "495520  [This, stuff, is, the, best, ., I, put, it, on...  \n",
       "373115  [Organic, India, Tulsi, tea, is, ,, to, me, ,,...  \n",
       "547017  [I, have, a, German, Shorthaired, Pointer, (, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization Using NLTK\n",
    "food_review_text_1k['tokenized_reviews'] = food_review_text_1k['Text'].apply(nltk.word_tokenize)\n",
    "food_review_text_1k.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chips'}\n"
     ]
    }
   ],
   "source": [
    "# Word Search Using Regex\n",
    "search_word = set([w for w in food_review_text_1k['tokenized_reviews'].iloc[0] if re.search('^c.i..$', w)])\n",
    "print(search_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>tokenized_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>277535</th>\n",
       "      <td>I love these chips! They always make a great h...</td>\n",
       "      <td>[I, love, these, chips, !, They, always, make,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547017</th>\n",
       "      <td>I have a German Shorthaired Pointer (3 yrs old...</td>\n",
       "      <td>[I, have, a, German, Shorthaired, Pointer, (, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153491</th>\n",
       "      <td>Our GreatDane loves these , he's never happy w...</td>\n",
       "      <td>[Our, GreatDane, loves, these, ,, he, 's, neve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307887</th>\n",
       "      <td>My parents' dog refused to take her medicine u...</td>\n",
       "      <td>[My, parents, ', dog, refused, to, take, her, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189614</th>\n",
       "      <td>Like most of the other reviews state, you can ...</td>\n",
       "      <td>[Like, most, of, the, other, reviews, state, ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362712</th>\n",
       "      <td>We own two dogs who are drastically different ...</td>\n",
       "      <td>[We, own, two, dogs, who, are, drastically, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564730</th>\n",
       "      <td>A friend's daughter has just gone to college. ...</td>\n",
       "      <td>[A, friend, 's, daughter, has, just, gone, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353896</th>\n",
       "      <td>Scents:&lt;br /&gt;Cool Impact&lt;br /&gt;Arctic Edge - my...</td>\n",
       "      <td>[Scents, :, &lt;, br, /, &gt;, Cool, Impact, &lt;, br, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87831</th>\n",
       "      <td>My little diabetic shih-tzu, Lily, is notoriou...</td>\n",
       "      <td>[My, little, diabetic, shih-tzu, ,, Lily, ,, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291616</th>\n",
       "      <td>This tastes great on chicken and shrimp and is...</td>\n",
       "      <td>[This, tastes, great, on, chicken, and, shrimp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48717</th>\n",
       "      <td>This is great tasting Organic Honey.  I will d...</td>\n",
       "      <td>[This, is, great, tasting, Organic, Honey, ., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40295</th>\n",
       "      <td>this was great....I gave it to my daughter she...</td>\n",
       "      <td>[this, was, great, ..., .I, gave, it, to, my, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436373</th>\n",
       "      <td>Not bad...just a little bland and not much in ...</td>\n",
       "      <td>[Not, bad, ..., just, a, little, bland, and, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360593</th>\n",
       "      <td>My Mom is a great biscotti baker, she has trad...</td>\n",
       "      <td>[My, Mom, is, a, great, biscotti, baker, ,, sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291157</th>\n",
       "      <td>Use all flavors to flavor food without calorie...</td>\n",
       "      <td>[Use, all, flavors, to, flavor, food, without,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482514</th>\n",
       "      <td>For not having great knowledge on being health...</td>\n",
       "      <td>[For, not, having, great, knowledge, on, being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290499</th>\n",
       "      <td>This tea has a good flavor--not too strong or ...</td>\n",
       "      <td>[This, tea, has, a, good, flavor, --, not, too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41548</th>\n",
       "      <td>I really love these crackers.  I'm not much of...</td>\n",
       "      <td>[I, really, love, these, crackers, ., I, 'm, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460883</th>\n",
       "      <td>Before I ordered these, I had never had white ...</td>\n",
       "      <td>[Before, I, ordered, these, ,, I, had, never, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289189</th>\n",
       "      <td>This product is awesome.  We had purchased thi...</td>\n",
       "      <td>[This, product, is, awesome, ., We, had, purch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560819</th>\n",
       "      <td>I bought this item recently, and amazon had a ...</td>\n",
       "      <td>[I, bought, this, item, recently, ,, and, amaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115275</th>\n",
       "      <td>They carry this at Walmart and it's outstandin...</td>\n",
       "      <td>[They, carry, this, at, Walmart, and, it, 's, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3023</th>\n",
       "      <td>This product is both effective and convenient....</td>\n",
       "      <td>[This, product, is, both, effective, and, conv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409706</th>\n",
       "      <td>This pizza crust is easy to make and has a goo...</td>\n",
       "      <td>[This, pizza, crust, is, easy, to, make, and, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310389</th>\n",
       "      <td>These bars make a great breakfast or snack. Pa...</td>\n",
       "      <td>[These, bars, make, a, great, breakfast, or, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65884</th>\n",
       "      <td>Zukes is a treat my puppy loves and is good fo...</td>\n",
       "      <td>[Zukes, is, a, treat, my, puppy, loves, and, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473907</th>\n",
       "      <td>My daughter is almost 5 and has been gluten fr...</td>\n",
       "      <td>[My, daughter, is, almost, 5, and, has, been, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16566</th>\n",
       "      <td>I've been eating this for several months now. ...</td>\n",
       "      <td>[I, 've, been, eating, this, for, several, mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231731</th>\n",
       "      <td>I got them buy one, get one free and it was a ...</td>\n",
       "      <td>[I, got, them, buy, one, ,, get, one, free, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15495</th>\n",
       "      <td>My dog loves these treats. He's really picking...</td>\n",
       "      <td>[My, dog, loves, these, treats, ., He, 's, rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490803</th>\n",
       "      <td>Great tasting fat free hot chocolate!  The pac...</td>\n",
       "      <td>[Great, tasting, fat, free, hot, chocolate, !,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375144</th>\n",
       "      <td>Great seller. The product was as described.  T...</td>\n",
       "      <td>[Great, seller, ., The, product, was, as, desc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442452</th>\n",
       "      <td>I've tried a number of Green Teas but without ...</td>\n",
       "      <td>[I, 've, tried, a, number, of, Green, Teas, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46418</th>\n",
       "      <td>Excellent product. Tastes great even if you do...</td>\n",
       "      <td>[Excellent, product, ., Tastes, great, even, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364443</th>\n",
       "      <td>I've used cases of these popcorn portion packs...</td>\n",
       "      <td>[I, 've, used, cases, of, these, popcorn, port...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308659</th>\n",
       "      <td>I love Newman's Own blends, organic, great-tas...</td>\n",
       "      <td>[I, love, Newman, 's, Own, blends, ,, organic,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278450</th>\n",
       "      <td>There aren't quite enough adjectives to descri...</td>\n",
       "      <td>[There, are, n't, quite, enough, adjectives, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395402</th>\n",
       "      <td>I decided to try this dry food on my two dogs,...</td>\n",
       "      <td>[I, decided, to, try, this, dry, food, on, my,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86103</th>\n",
       "      <td>Not sure if they were ot not but they didn't h...</td>\n",
       "      <td>[Not, sure, if, they, were, ot, not, but, they...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83454</th>\n",
       "      <td>I was so excited to get my box of Fog Chaser. ...</td>\n",
       "      <td>[I, was, so, excited, to, get, my, box, of, Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467297</th>\n",
       "      <td>This is an excellent crema coffee.  It is perf...</td>\n",
       "      <td>[This, is, an, excellent, crema, coffee, ., It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326930</th>\n",
       "      <td>I started buying these as a \"to go\" snack for ...</td>\n",
       "      <td>[I, started, buying, these, as, a, ``, to, go,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255937</th>\n",
       "      <td>If you follow correct method of preparing (let...</td>\n",
       "      <td>[If, you, follow, correct, method, of, prepari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128236</th>\n",
       "      <td>This truly is a wonderful, multi-purpose produ...</td>\n",
       "      <td>[This, truly, is, a, wonderful, ,, multi-purpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469319</th>\n",
       "      <td>I pay over $5 per jar at a local market. Such ...</td>\n",
       "      <td>[I, pay, over, $, 5, per, jar, at, a, local, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379136</th>\n",
       "      <td>i was a skeptic of this product when i first m...</td>\n",
       "      <td>[i, was, a, skeptic, of, this, product, when, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342261</th>\n",
       "      <td>Great product!&lt;br /&gt;&lt;br /&gt;It is claimed that t...</td>\n",
       "      <td>[Great, product, !, &lt;, br, /, &gt;, &lt;, br, /, &gt;, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9920</th>\n",
       "      <td>I started adding chia seeds to my diet about 1...</td>\n",
       "      <td>[I, started, adding, chia, seeds, to, my, diet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528372</th>\n",
       "      <td>One of the best boxed side dish I have ever us...</td>\n",
       "      <td>[One, of, the, best, boxed, side, dish, I, hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531807</th>\n",
       "      <td>This is absolutely as good as French vanilla c...</td>\n",
       "      <td>[This, is, absolutely, as, good, as, French, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91184</th>\n",
       "      <td>If  you are looking for a really bold cup of c...</td>\n",
       "      <td>[If, you, are, looking, for, a, really, bold, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196306</th>\n",
       "      <td>Keebler Chips Deluxe Coconut,18-Ounce Packages...</td>\n",
       "      <td>[Keebler, Chips, Deluxe, Coconut,18-Ounce, Pac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82340</th>\n",
       "      <td>Seriously,  I like this product a lot, and thi...</td>\n",
       "      <td>[Seriously, ,, I, like, this, product, a, lot,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177009</th>\n",
       "      <td>I chose these cookies because I was lead to be...</td>\n",
       "      <td>[I, chose, these, cookies, because, I, was, le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524322</th>\n",
       "      <td>And that can't really be bad, can it? This is ...</td>\n",
       "      <td>[And, that, ca, n't, really, be, bad, ,, can, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319110</th>\n",
       "      <td>These chips are great and so is the price! Oth...</td>\n",
       "      <td>[These, chips, are, great, and, so, is, the, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548470</th>\n",
       "      <td>I have been subscribing to this carrots puree ...</td>\n",
       "      <td>[I, have, been, subscribing, to, this, carrots...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67817</th>\n",
       "      <td>These are a favorite at our home. We like the ...</td>\n",
       "      <td>[These, are, a, favorite, at, our, home, ., We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92102</th>\n",
       "      <td>The new Cheesy Skillets dinner mix from Velvet...</td>\n",
       "      <td>[The, new, Cheesy, Skillets, dinner, mix, from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189420</th>\n",
       "      <td>Both are organic and cold-pressed. &lt;a href=\"ht...</td>\n",
       "      <td>[Both, are, organic, and, cold-pressed, ., &lt;, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  \\\n",
       "277535  I love these chips! They always make a great h...   \n",
       "547017  I have a German Shorthaired Pointer (3 yrs old...   \n",
       "153491  Our GreatDane loves these , he's never happy w...   \n",
       "307887  My parents' dog refused to take her medicine u...   \n",
       "189614  Like most of the other reviews state, you can ...   \n",
       "362712  We own two dogs who are drastically different ...   \n",
       "564730  A friend's daughter has just gone to college. ...   \n",
       "353896  Scents:<br />Cool Impact<br />Arctic Edge - my...   \n",
       "87831   My little diabetic shih-tzu, Lily, is notoriou...   \n",
       "291616  This tastes great on chicken and shrimp and is...   \n",
       "48717   This is great tasting Organic Honey.  I will d...   \n",
       "40295   this was great....I gave it to my daughter she...   \n",
       "436373  Not bad...just a little bland and not much in ...   \n",
       "360593  My Mom is a great biscotti baker, she has trad...   \n",
       "291157  Use all flavors to flavor food without calorie...   \n",
       "482514  For not having great knowledge on being health...   \n",
       "290499  This tea has a good flavor--not too strong or ...   \n",
       "41548   I really love these crackers.  I'm not much of...   \n",
       "460883  Before I ordered these, I had never had white ...   \n",
       "289189  This product is awesome.  We had purchased thi...   \n",
       "560819  I bought this item recently, and amazon had a ...   \n",
       "115275  They carry this at Walmart and it's outstandin...   \n",
       "3023    This product is both effective and convenient....   \n",
       "409706  This pizza crust is easy to make and has a goo...   \n",
       "310389  These bars make a great breakfast or snack. Pa...   \n",
       "65884   Zukes is a treat my puppy loves and is good fo...   \n",
       "473907  My daughter is almost 5 and has been gluten fr...   \n",
       "16566   I've been eating this for several months now. ...   \n",
       "231731  I got them buy one, get one free and it was a ...   \n",
       "15495   My dog loves these treats. He's really picking...   \n",
       "...                                                   ...   \n",
       "490803  Great tasting fat free hot chocolate!  The pac...   \n",
       "375144  Great seller. The product was as described.  T...   \n",
       "442452  I've tried a number of Green Teas but without ...   \n",
       "46418   Excellent product. Tastes great even if you do...   \n",
       "364443  I've used cases of these popcorn portion packs...   \n",
       "308659  I love Newman's Own blends, organic, great-tas...   \n",
       "278450  There aren't quite enough adjectives to descri...   \n",
       "395402  I decided to try this dry food on my two dogs,...   \n",
       "86103   Not sure if they were ot not but they didn't h...   \n",
       "83454   I was so excited to get my box of Fog Chaser. ...   \n",
       "467297  This is an excellent crema coffee.  It is perf...   \n",
       "326930  I started buying these as a \"to go\" snack for ...   \n",
       "255937  If you follow correct method of preparing (let...   \n",
       "128236  This truly is a wonderful, multi-purpose produ...   \n",
       "469319  I pay over $5 per jar at a local market. Such ...   \n",
       "379136  i was a skeptic of this product when i first m...   \n",
       "342261  Great product!<br /><br />It is claimed that t...   \n",
       "9920    I started adding chia seeds to my diet about 1...   \n",
       "528372  One of the best boxed side dish I have ever us...   \n",
       "531807  This is absolutely as good as French vanilla c...   \n",
       "91184   If  you are looking for a really bold cup of c...   \n",
       "196306  Keebler Chips Deluxe Coconut,18-Ounce Packages...   \n",
       "82340   Seriously,  I like this product a lot, and thi...   \n",
       "177009  I chose these cookies because I was lead to be...   \n",
       "524322  And that can't really be bad, can it? This is ...   \n",
       "319110  These chips are great and so is the price! Oth...   \n",
       "548470  I have been subscribing to this carrots puree ...   \n",
       "67817   These are a favorite at our home. We like the ...   \n",
       "92102   The new Cheesy Skillets dinner mix from Velvet...   \n",
       "189420  Both are organic and cold-pressed. <a href=\"ht...   \n",
       "\n",
       "                                        tokenized_reviews  \n",
       "277535  [I, love, these, chips, !, They, always, make,...  \n",
       "547017  [I, have, a, German, Shorthaired, Pointer, (, ...  \n",
       "153491  [Our, GreatDane, loves, these, ,, he, 's, neve...  \n",
       "307887  [My, parents, ', dog, refused, to, take, her, ...  \n",
       "189614  [Like, most, of, the, other, reviews, state, ,...  \n",
       "362712  [We, own, two, dogs, who, are, drastically, di...  \n",
       "564730  [A, friend, 's, daughter, has, just, gone, to,...  \n",
       "353896  [Scents, :, <, br, /, >, Cool, Impact, <, br, ...  \n",
       "87831   [My, little, diabetic, shih-tzu, ,, Lily, ,, i...  \n",
       "291616  [This, tastes, great, on, chicken, and, shrimp...  \n",
       "48717   [This, is, great, tasting, Organic, Honey, ., ...  \n",
       "40295   [this, was, great, ..., .I, gave, it, to, my, ...  \n",
       "436373  [Not, bad, ..., just, a, little, bland, and, n...  \n",
       "360593  [My, Mom, is, a, great, biscotti, baker, ,, sh...  \n",
       "291157  [Use, all, flavors, to, flavor, food, without,...  \n",
       "482514  [For, not, having, great, knowledge, on, being...  \n",
       "290499  [This, tea, has, a, good, flavor, --, not, too...  \n",
       "41548   [I, really, love, these, crackers, ., I, 'm, n...  \n",
       "460883  [Before, I, ordered, these, ,, I, had, never, ...  \n",
       "289189  [This, product, is, awesome, ., We, had, purch...  \n",
       "560819  [I, bought, this, item, recently, ,, and, amaz...  \n",
       "115275  [They, carry, this, at, Walmart, and, it, 's, ...  \n",
       "3023    [This, product, is, both, effective, and, conv...  \n",
       "409706  [This, pizza, crust, is, easy, to, make, and, ...  \n",
       "310389  [These, bars, make, a, great, breakfast, or, s...  \n",
       "65884   [Zukes, is, a, treat, my, puppy, loves, and, i...  \n",
       "473907  [My, daughter, is, almost, 5, and, has, been, ...  \n",
       "16566   [I, 've, been, eating, this, for, several, mon...  \n",
       "231731  [I, got, them, buy, one, ,, get, one, free, an...  \n",
       "15495   [My, dog, loves, these, treats, ., He, 's, rea...  \n",
       "...                                                   ...  \n",
       "490803  [Great, tasting, fat, free, hot, chocolate, !,...  \n",
       "375144  [Great, seller, ., The, product, was, as, desc...  \n",
       "442452  [I, 've, tried, a, number, of, Green, Teas, bu...  \n",
       "46418   [Excellent, product, ., Tastes, great, even, i...  \n",
       "364443  [I, 've, used, cases, of, these, popcorn, port...  \n",
       "308659  [I, love, Newman, 's, Own, blends, ,, organic,...  \n",
       "278450  [There, are, n't, quite, enough, adjectives, t...  \n",
       "395402  [I, decided, to, try, this, dry, food, on, my,...  \n",
       "86103   [Not, sure, if, they, were, ot, not, but, they...  \n",
       "83454   [I, was, so, excited, to, get, my, box, of, Fo...  \n",
       "467297  [This, is, an, excellent, crema, coffee, ., It...  \n",
       "326930  [I, started, buying, these, as, a, ``, to, go,...  \n",
       "255937  [If, you, follow, correct, method, of, prepari...  \n",
       "128236  [This, truly, is, a, wonderful, ,, multi-purpo...  \n",
       "469319  [I, pay, over, $, 5, per, jar, at, a, local, m...  \n",
       "379136  [i, was, a, skeptic, of, this, product, when, ...  \n",
       "342261  [Great, product, !, <, br, /, >, <, br, /, >, ...  \n",
       "9920    [I, started, adding, chia, seeds, to, my, diet...  \n",
       "528372  [One, of, the, best, boxed, side, dish, I, hav...  \n",
       "531807  [This, is, absolutely, as, good, as, French, v...  \n",
       "91184   [If, you, are, looking, for, a, really, bold, ...  \n",
       "196306  [Keebler, Chips, Deluxe, Coconut,18-Ounce, Pac...  \n",
       "82340   [Seriously, ,, I, like, this, product, a, lot,...  \n",
       "177009  [I, chose, these, cookies, because, I, was, le...  \n",
       "524322  [And, that, ca, n't, really, be, bad, ,, can, ...  \n",
       "319110  [These, chips, are, great, and, so, is, the, p...  \n",
       "548470  [I, have, been, subscribing, to, this, carrots...  \n",
       "67817   [These, are, a, favorite, at, our, home, ., We...  \n",
       "92102   [The, new, Cheesy, Skillets, dinner, mix, from...  \n",
       "189420  [Both, are, organic, and, cold-pressed, ., <, ...  \n",
       "\n",
       "[218 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word Search Using the Exact Word\n",
    "#Search for the word \"great\" in reviews\n",
    "# The rows of the reviews containing the word will be retrieved. They can be considered a positive review. \n",
    "food_review_text_1k[food_review_text_1k['Text'].str.contains('great')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "{'at', 'sustenance', 'make', \"'m\", 'a', 'stuck', 'healthy', 'chips', 'love', 'the', '!', 'just', 'snack', 'I', '.', 'vending', 'machine', 'work', 'for', 'always', 'when', 'with', 'They', 'these', 'great'}\n",
      "After Porter Stemmer:\n",
      "['at', 'susten', 'make', \"'m\", 'a', 'stuck', 'healthi', 'chip', 'love', 'the', '!', 'just', 'snack', 'I', '.', 'vend', 'machin', 'work', 'for', 'alway', 'when', 'with', 'they', 'these', 'great']\n",
      "After Lancaster Stemmer:\n",
      "['at', 'sust', 'mak', \"'m\", 'a', 'stuck', 'healthy', 'chip', 'lov', 'the', '!', 'just', 'snack', 'i', '.', 'vend', 'machin', 'work', 'for', 'alway', 'when', 'with', 'they', 'thes', 'gre']\n"
     ]
    }
   ],
   "source": [
    "# Normalization Using NLTK\n",
    "# stemming or normalization\n",
    "#  NLTK provides two functions implementing the stemming algorithm. The first is the Porter Stemming algorithm, \n",
    "# and the second is the Lancaster stemmer\n",
    "print(\"Before\")\n",
    "words = set(food_review_text_1k['tokenized_reviews'].iloc[0])\n",
    "print(words)\n",
    "\n",
    "print(\"After Porter Stemmer:\")\n",
    "porter = nltk.PorterStemmer()\n",
    "print([porter.stem(w) for w in words])\n",
    "\n",
    "print(\"After Lancaster Stemmer:\")\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "print([lancaster.stem(w) for w in words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steeming all tokens in data frame\n",
    "\n",
    "def stem_sentences(tokenslist):\n",
    "#     tokens = sentence.split()\n",
    "    import nltk\n",
    "    porter = nltk.PorterStemmer()\n",
    "    stemmed_tokens = [porter.stem(token) for token in tokenslist]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "\n",
    "food_review_text_1k['stemming_tokens'] = food_review_text_1k['tokenized_reviews'].apply(stem_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text                 I love these chips! They always make a great h...\n",
       "tokenized_reviews    [I, love, these, chips, !, They, always, make,...\n",
       "stemming_tokens      I love these chip ! they alway make a great he...\n",
       "Name: 277535, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_review_text_1k.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  My/PRP$\n",
      "  English/JJ\n",
      "  Bulldog/NNP\n",
      "  Larry/NNP\n",
      "  had/VBD\n",
      "  skin/VBN\n",
      "  allergies/NNS\n",
      "  (NP the/DT summer/NN)\n",
      "  we/PRP\n",
      "  got/VBD\n",
      "  him/PRP\n",
      "  at/IN\n",
      "  (NP age/NN)\n",
      "  3/CD\n",
      "  ,/,\n",
      "  I/PRP\n",
      "  'm/VBP\n",
      "  so/RB\n",
      "  glad/JJ\n",
      "  that/IN\n",
      "  now/RB\n",
      "  I/PRP\n",
      "  can/MD\n",
      "  buy/VB\n",
      "  his/PRP$\n",
      "  (NP food/NN)\n",
      "  from/IN\n",
      "  Amazon/NNP)\n"
     ]
    }
   ],
   "source": [
    "# Noun phase chunking\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "text = word_tokenize(\"My English Bulldog Larry had skin allergies the summer we got him at age 3, I'm so glad that now I can buy his food from Amazon\")\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "review_chunking_out = cp.parse(nltk.pos_tag(text))\n",
    "print(review_chunking_out)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('My', 'PRP$', 'O'),\n",
      " ('English', 'JJ', 'O'),\n",
      " ('Bulldog', 'NNP', 'O'),\n",
      " ('Larry', 'NNP', 'O'),\n",
      " ('had', 'VBD', 'O'),\n",
      " ('skin', 'VBN', 'O'),\n",
      " ('allergies', 'NNS', 'O'),\n",
      " ('the', 'DT', 'B-NP'),\n",
      " ('summer', 'NN', 'I-NP'),\n",
      " ('we', 'PRP', 'O'),\n",
      " ('got', 'VBD', 'O'),\n",
      " ('him', 'PRP', 'O'),\n",
      " ('at', 'IN', 'O'),\n",
      " ('age', 'NN', 'B-NP'),\n",
      " ('3', 'CD', 'O'),\n",
      " (',', ',', 'O'),\n",
      " ('I', 'PRP', 'O'),\n",
      " (\"'m\", 'VBP', 'O'),\n",
      " ('so', 'RB', 'O'),\n",
      " ('glad', 'JJ', 'O'),\n",
      " ('that', 'IN', 'O'),\n",
      " ('now', 'RB', 'O'),\n",
      " ('I', 'PRP', 'O'),\n",
      " ('can', 'MD', 'O'),\n",
      " ('buy', 'VB', 'O'),\n",
      " ('his', 'PRP$', 'O'),\n",
      " ('food', 'NN', 'B-NP'),\n",
      " ('from', 'IN', 'O'),\n",
      " ('Amazon', 'NNP', 'O')]\n"
     ]
    }
   ],
   "source": [
    "# IOB tag representation of chunking  I (Inside), O (Outside), and B(Begin).\n",
    "\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from pprint import pprint\n",
    "\n",
    "#Print IOB tags\n",
    "review_chunking_out_IOB = tree2conlltags(review_chunking_out)\n",
    "pprint(review_chunking_out_IOB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('M', 'NNP'), ('y', 'PRP'), (' ', 'VBP'), ('E', 'NNP'), ('n', 'FW'), ('g', 'NN'), ('l', 'NN'), ('i', 'NN'), ('s', 'VBP'), ('h', 'NN'), (' ', 'NN'), ('B', 'NNP'), ('u', 'NN'), ('l', 'NN'), ('l', 'NN'), ('d', 'NN'), ('o', 'NN'), ('g', 'NN'), (' ', 'NNP'), ('L', 'NNP'), ('a', 'DT'), ('r', 'NN'), ('r', 'NN'), ('y', 'NN'), (' ', 'NNP'), ('h', 'VBZ'), ('a', 'DT'), ('d', 'NN'), (' ', 'NN'), ('s', 'NN'), ('k', 'NN'), ('i', 'JJ'), ('n', 'VBP'), (' ', 'PDT'), ('a', 'DT'), ('l', 'NN'), ('l', 'NN'), ('e', 'NN'), ('r', 'NN'), ('g', 'NN'), ('i', 'NN'), ('e', 'VBP'), ('s', 'JJ'), (' ', 'NNP'), ('t', 'NN'), ('h', 'NN'), ('e', 'NN'), (' ', 'NNP'), ('s', 'NN'), ('u', 'JJ'), ('m', 'NN'), ('m', 'NN'), ('e', 'NN'), ('r', 'NN'), (' ', 'NNP'), ('w', 'NN'), ('e', 'NN'), (' ', 'NNP'), ('g', 'NN'), ('o', 'NN'), ('t', 'NN'), (' ', 'NNP'), ('h', 'NN'), ('i', 'NN'), ('m', 'VBP'), (' ', 'PDT'), ('a', 'DT'), ('t', 'NN'), (' ', 'VBZ'), ('a', 'DT'), ('g', 'NN'), ('e', 'NN'), (' ', 'VBD'), ('3', 'CD'), (',', ','), (' ', 'FW'), ('I', 'PRP'), (\"'\", \"''\"), ('m', 'JJ'), (' ', 'NNP'), ('s', 'NN'), ('o', 'NN'), (' ', 'NNP'), ('g', 'NN'), ('l', 'NN'), ('a', 'DT'), ('d', 'NN'), (' ', 'NNP'), ('t', 'NN'), ('h', 'VBD'), ('a', 'DT'), ('t', 'NN'), (' ', 'NNP'), ('n', 'CC'), ('o', 'JJ'), ('w', 'NN'), (' ', 'NN'), ('I', 'PRP'), (' ', 'VBP'), ('c', 'VBG'), ('a', 'DT'), ('n', 'JJ'), (' ', 'NN'), ('b', 'NN'), ('u', 'JJ'), ('y', 'NN'), (' ', 'NNP'), ('h', 'NN'), ('i', 'NN'), ('s', 'VBP'), (' ', 'JJ'), ('f', 'NN'), ('o', 'NN'), ('o', 'NN'), ('d', 'NN'), (' ', 'NNP'), ('f', 'NN'), ('r', 'NN'), ('o', 'IN'), ('m', 'NN'), (' ', 'VBP'), ('A', 'NNP'), ('m', 'NN'), ('a', 'DT'), ('z', 'NN'), ('o', 'NN'), ('n', 'NN')]\n",
      "*******************************************************NER***********************************************************\n",
      "(S\n",
      "  M/NNP\n",
      "  y/PRP\n",
      "   /VBP\n",
      "  E/NNP\n",
      "  n/FW\n",
      "  g/NN\n",
      "  l/NN\n",
      "  i/NN\n",
      "  s/VBP\n",
      "  h/NN\n",
      "   /NN\n",
      "  B/NNP\n",
      "  u/NN\n",
      "  l/NN\n",
      "  l/NN\n",
      "  d/NN\n",
      "  o/NN\n",
      "  g/NN\n",
      "   /NNP\n",
      "  L/NNP\n",
      "  a/DT\n",
      "  r/NN\n",
      "  r/NN\n",
      "  y/NN\n",
      "   /NNP\n",
      "  h/VBZ\n",
      "  a/DT\n",
      "  d/NN\n",
      "   /NN\n",
      "  s/NN\n",
      "  k/NN\n",
      "  i/JJ\n",
      "  n/VBP\n",
      "   /PDT\n",
      "  a/DT\n",
      "  l/NN\n",
      "  l/NN\n",
      "  e/NN\n",
      "  r/NN\n",
      "  g/NN\n",
      "  i/NN\n",
      "  e/VBP\n",
      "  s/JJ\n",
      "   /NNP\n",
      "  t/NN\n",
      "  h/NN\n",
      "  e/NN\n",
      "   /NNP\n",
      "  s/NN\n",
      "  u/JJ\n",
      "  m/NN\n",
      "  m/NN\n",
      "  e/NN\n",
      "  r/NN\n",
      "   /NNP\n",
      "  w/NN\n",
      "  e/NN\n",
      "   /NNP\n",
      "  g/NN\n",
      "  o/NN\n",
      "  t/NN\n",
      "   /NNP\n",
      "  h/NN\n",
      "  i/NN\n",
      "  m/VBP\n",
      "   /PDT\n",
      "  a/DT\n",
      "  t/NN\n",
      "   /VBZ\n",
      "  a/DT\n",
      "  g/NN\n",
      "  e/NN\n",
      "   /VBD\n",
      "  3/CD\n",
      "  ,/,\n",
      "   /FW\n",
      "  I/PRP\n",
      "  '/''\n",
      "  m/JJ\n",
      "   /NNP\n",
      "  s/NN\n",
      "  o/NN\n",
      "   /NNP\n",
      "  g/NN\n",
      "  l/NN\n",
      "  a/DT\n",
      "  d/NN\n",
      "   /NNP\n",
      "  t/NN\n",
      "  h/VBD\n",
      "  a/DT\n",
      "  t/NN\n",
      "   /NNP\n",
      "  n/CC\n",
      "  o/JJ\n",
      "  w/NN\n",
      "   /NN\n",
      "  I/PRP\n",
      "   /VBP\n",
      "  c/VBG\n",
      "  a/DT\n",
      "  n/JJ\n",
      "   /NN\n",
      "  b/NN\n",
      "  u/JJ\n",
      "  y/NN\n",
      "   /NNP\n",
      "  h/NN\n",
      "  i/NN\n",
      "  s/VBP\n",
      "   /JJ\n",
      "  f/NN\n",
      "  o/NN\n",
      "  o/NN\n",
      "  d/NN\n",
      "   /NNP\n",
      "  f/NN\n",
      "  r/NN\n",
      "  o/IN\n",
      "  m/NN\n",
      "   /VBP\n",
      "  A/NNP\n",
      "  m/NN\n",
      "  a/DT\n",
      "  z/NN\n",
      "  o/NN\n",
      "  n/NN)\n"
     ]
    }
   ],
   "source": [
    "# POS tagging (Parts of speech)\n",
    "text = \"My English Bulldog Larry had skin allergies the summer we got him at age 3, I'm so glad that now I can buy his food from Amazon\"\n",
    "tagged_review_sent = nltk.pos_tag(text)\n",
    "print(tagged_review_sent)\n",
    "print(\"*******************************************************NER***********************************************************\")\n",
    "print(nltk.ne_chunk(tagged_review_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging and NER\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My PRP$\n",
      "English NNP\n",
      "Bulldog NNP\n",
      "Larry NNP\n",
      "had VBD\n",
      "skin NN\n",
      "allergies NNS\n",
      "the DT\n",
      "summer NN\n",
      "we PRP\n",
      "got VBD\n",
      "him PRP\n",
      "at IN\n",
      "age NN\n",
      "3 CD\n",
      ", ,\n",
      "I PRP\n",
      "'m VBP\n",
      "so RB\n",
      "glad JJ\n",
      "that IN\n",
      "now RB\n",
      "I PRP\n",
      "can MD\n",
      "buy VB\n",
      "his PRP$\n",
      "food NN\n",
      "from IN\n",
      "Amazon NNP\n"
     ]
    }
   ],
   "source": [
    "#  POS tagging\n",
    "text = \"My English Bulldog Larry had skin allergies the summer we got him at age 3, I'm so glad that now I can buy his food from Amazon\"\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My English Bulldog Larry Larry nsubj had\n",
      "skin allergies allergies dobj had\n",
      "we we nsubj got\n",
      "him him dobj got\n",
      "age age pobj at\n",
      "I I nsubj 'm\n",
      "I I nsubj buy\n",
      "his food food dobj buy\n",
      "Amazon Amazon pobj from\n"
     ]
    }
   ],
   "source": [
    "# Dependency Parsing\n",
    "for chunk in doc.noun_chunks:\n",
    "     print(chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"4b3c74ad4bcf4fe885c410c75f20852e-0\" class=\"displacy\" width=\"2675\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">My</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">English</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Bulldog</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Larry</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">had</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">skin</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">allergies</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">summer</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">we</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">got</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">him</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">age</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">3</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,89.5 570.0,89.5 570.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,177.0 565.0,177.0 565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-3\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-4\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,354.0 L937,342.0 953,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-5\" stroke-width=\"2px\" d=\"M770,352.0 C770,177.0 1090.0,177.0 1090.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1090.0,354.0 L1098.0,342.0 1082.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-7\" stroke-width=\"2px\" d=\"M770,352.0 C770,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-8\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,264.5 1785.0,264.5 1785.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,354.0 L1637,342.0 1653,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-9\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,177.0 1790.0,177.0 1790.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1790.0,354.0 L1798.0,342.0 1782.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-10\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,264.5 1960.0,264.5 1960.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1960.0,354.0 L1968.0,342.0 1952.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-11\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,177.0 2140.0,177.0 2140.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2140.0,354.0 L2148.0,342.0 2132.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-12\" stroke-width=\"2px\" d=\"M2170,352.0 C2170,264.5 2310.0,264.5 2310.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2310.0,354.0 L2318.0,342.0 2302.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-13\" stroke-width=\"2px\" d=\"M2345,352.0 C2345,264.5 2485.0,264.5 2485.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4b3c74ad4bcf4fe885c410c75f20852e-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2485.0,354.0 L2493.0,342.0 2477.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dependency tree\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "doc = nlp(\"My English Bulldog Larry had skin allergies the summer we got him at age 3\")\n",
    "displacy.render(doc, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun phrases: ['My English Bulldog Larry', 'skin allergies', 'we', 'him', 'age', 'I', 'I', 'his food', 'Amazon']\n",
      "Verbs: ['have', 'get', 'be', 'can', 'buy']\n"
     ]
    }
   ],
   "source": [
    "# Chunking\n",
    "#  Extract VERB and NOUN\n",
    "text = (\"My English Bulldog Larry had skin allergies the summer we got him at age 3, I'm so glad that now I can buy his food from Amazon\")\n",
    "doc = nlp(text)\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 CARDINAL\n"
     ]
    }
   ],
   "source": [
    "# Named Entity Recognition\n",
    "# Load English tokenizer, tagger, parser, NER, and word vectors\n",
    "nlp = spacy.load(\"en\")\n",
    "# Process whole documents\n",
    "text = (\"I want to buy a Mobile within range 1500\")\n",
    "doc = nlp(text)\n",
    "# Find named entities\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoreNLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We skip corenlp rather we focus more on Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also skip TextBlob rather we focus more on Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Building', 'an']),\n",
       " WordList(['an', 'enterprise']),\n",
       " WordList(['enterprise', 'chatbot']),\n",
       " WordList(['chatbot', 'that']),\n",
       " WordList(['that', 'can']),\n",
       " WordList(['can', 'converse']),\n",
       " WordList(['converse', 'like']),\n",
       " WordList(['like', 'humans'])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating n-grams from a sentence\n",
    "\n",
    "from textblob import TextBlob\n",
    "blob = TextBlob(\"Building an enterprise chatbot that can converse like humans\")\n",
    "blob.ngrams(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright then. If you have contact information about AI, also chatbots.\n",
      "Hmm learn from that\n",
      "Hi! Nice to hear that song?\n",
      "My goals are to be able to use getUpdates or switch to webhooks for my bot?\n",
      "What is that there is always a difficult think to do luandry. Almost everyday 😊😊\n",
      "nice to talk with 😁\n",
      "Hi! How are you talking about binding the interface on Qt\n",
      "russian, I think this tool will be so scary 😵😵😵\n",
      "Nice! Humans really love him!! 😊😊\n",
      "What do you think you are about it.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import markovify\n",
    "\n",
    "data = pd.read_csv('conversation_data.csv', usecols=['text'],  skiprows = [1])\n",
    "newData = data['text'].values.tolist()\n",
    "\n",
    "# print(newData[:5])\n",
    "text_model = markovify.NewlineText(newData, state_size = 2)\n",
    "\n",
    "#Generate random text\n",
    "for i in range(10):\n",
    "    print(text_model.make_sentence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
